{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed637941-7d20-4bb6-b403-52709b803f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 86ms/step - accuracy: 0.6986 - loss: 0.5397 - val_accuracy: 0.8616 - val_loss: 0.3407\n",
      "Epoch 2/3\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 90ms/step - accuracy: 0.9058 - loss: 0.2530 - val_accuracy: 0.8722 - val_loss: 0.3083\n",
      "Epoch 3/3\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 67ms/step - accuracy: 0.9336 - loss: 0.1838 - val_accuracy: 0.8656 - val_loss: 0.3280\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.8585 - loss: 0.3434\n",
      "\n",
      "Test Accuracy: 86.06%\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analyis using NLP on Imdb Movie reviews \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#parameters\n",
    "vocab_size = 10000\n",
    "max_length = 200\n",
    "embedding_dim = 16\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "#Load and process data\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "#Pad sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "#initialize model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#Train model\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_split=0.2)\n",
    "\n",
    "\n",
    "#Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Prediction function\n",
    "def predict_sentiment(text):\n",
    "    word_index = imdb.get_word_index()\n",
    "    text = text.lower().split()\n",
    "    text = [word_index[word] if word in word_index and word_index[word] < vocab_size else 0 for word in text]\n",
    "    text = pad_sequences([text], maxlen=max_length)\n",
    "    prediction = model.predict(text)\n",
    "    return \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd4e63-0181-4978-a2aa-f7fa012539ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
